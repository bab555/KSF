"""
CoD V6 Metrics - è¯„ä¼°æŒ‡æ ‡
ä¸“é—¨ä¸ºV6æ¶æ„è®¾è®¡çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬Flowè´¨é‡ã€æ³¨æ„åŠ›å¤šæ ·æ€§ã€æ€ç»´è´¨é‡ç­‰
"""

import torch
import torch.nn.functional as F
from typing import Dict, Any, Optional, List
import numpy as np
from collections import defaultdict


class CoDMetrics:
    """
    CoD V6æ¶æ„çš„è¯„ä¼°æŒ‡æ ‡ç±»
    
    åŒ…å«ä»¥ä¸‹æ ¸å¿ƒæŒ‡æ ‡ï¼š
    1. Flowè´¨é‡æŒ‡æ ‡ï¼šè¯„ä¼°ä¿¡æ¯åœ¨P-C-Sä¹‹é—´çš„æµåŠ¨è´¨é‡
    2. æ³¨æ„åŠ›å¤šæ ·æ€§ï¼šè¯„ä¼°32ä¸ªæ³¨æ„åŠ›å¤´çš„å¤šæ ·æ€§
    3. è§’è‰²åˆ†åŒ–æŒ‡æ ‡ï¼šç¡®ä¿Pã€Cã€Sä¿æŒä¸åŒçš„è§’è‰²
    4. æ€ç»´è´¨é‡è¯„ä¼°ï¼šè¯„ä¼°Sç”Ÿæˆçš„thinkingè´¨é‡
    5. éšå¼ä¼ é€’æ•ˆæœï¼šè¯„ä¼°roundtable attentionçš„æ•ˆæœ
    """
    
    def __init__(self):
        self.reset()
    
    def reset(self):
        """é‡ç½®æ‰€æœ‰æŒ‡æ ‡ç´¯ç§¯å™¨"""
        self.metrics_accumulator = defaultdict(list)
        self.batch_count = 0
    
    def compute_flow_quality(self, 
                           p_hidden: torch.Tensor,
                           c_hidden: torch.Tensor,
                           s_hidden: torch.Tensor) -> Dict[str, float]:
        """
        è®¡ç®—Flowè´¨é‡æŒ‡æ ‡
        
        Args:
            p_hidden: Proposerçš„éšçŠ¶æ€
            c_hidden: Challengerçš„éšçŠ¶æ€  
            s_hidden: Synthesizerçš„éšçŠ¶æ€
            
        Returns:
            flowè´¨é‡æŒ‡æ ‡å­—å…¸
        """
        with torch.no_grad():
            # ä¿¡æ¯ä¿ç•™åº¦ï¼šä»Påˆ°C
            p_to_c_retention = F.cosine_similarity(
                p_hidden.mean(dim=1), 
                c_hidden.mean(dim=1), 
                dim=-1
            ).mean().item()
            
            # ä¿¡æ¯å¢å¼ºåº¦ï¼šCç›¸å¯¹äºPçš„æ–°ä¿¡æ¯
            c_novelty = 1.0 - p_to_c_retention
            
            # ç»¼åˆæ•´åˆåº¦ï¼šSæ•´åˆPå’ŒCçš„ç¨‹åº¦
            s_integration = (
                F.cosine_similarity(s_hidden.mean(dim=1), p_hidden.mean(dim=1), dim=-1).mean() +
                F.cosine_similarity(s_hidden.mean(dim=1), c_hidden.mean(dim=1), dim=-1).mean()
            ).item() / 2.0
            
            # Flowè¿è´¯æ€§ï¼šæ•´ä½“ä¿¡æ¯æµçš„å¹³æ»‘åº¦
            flow_coherence = min(p_to_c_retention, s_integration)
            
            return {
                'p_to_c_retention': p_to_c_retention,
                'c_novelty': c_novelty,
                's_integration': s_integration,
                'flow_coherence': flow_coherence
            }
    
    def compute_attention_diversity(self,
                                  p_attention: Optional[torch.Tensor],
                                  c_attention: Optional[torch.Tensor],
                                  s_attention: Optional[torch.Tensor]) -> Dict[str, float]:
        """
        è®¡ç®—æ³¨æ„åŠ›å¤šæ ·æ€§æŒ‡æ ‡
        
        Args:
            p_attention: Pçš„æ³¨æ„åŠ›æ¨¡å¼ [batch, 10, seq, seq]
            c_attention: Cçš„æ³¨æ„åŠ›æ¨¡å¼ [batch, 10, seq, seq]
            s_attention: Sçš„æ³¨æ„åŠ›æ¨¡å¼ [batch, 12, seq, seq]
            
        Returns:
            æ³¨æ„åŠ›å¤šæ ·æ€§æŒ‡æ ‡
        """
        diversity_scores = {}
        
        def compute_head_diversity(attention_weights):
            """è®¡ç®—å•ä¸ªæ¨¡å—å†…æ³¨æ„åŠ›å¤´çš„å¤šæ ·æ€§"""
            if attention_weights is None:
                return 0.0
            
            batch_size, num_heads, seq_len, _ = attention_weights.shape
            
            # å°†æ³¨æ„åŠ›æƒé‡å±•å¹³
            attn_flat = attention_weights.view(batch_size, num_heads, -1)
            
            # è®¡ç®—ä¸åŒå¤´ä¹‹é—´çš„ç›¸ä¼¼åº¦
            similarities = []
            for i in range(num_heads):
                for j in range(i+1, num_heads):
                    sim = F.cosine_similarity(
                        attn_flat[:, i], 
                        attn_flat[:, j], 
                        dim=-1
                    ).mean()
                    similarities.append(sim)
            
            # å¤šæ ·æ€§ = 1 - å¹³å‡ç›¸ä¼¼åº¦
            avg_similarity = torch.stack(similarities).mean().item()
            return 1.0 - avg_similarity
        
        # è®¡ç®—å„æ¨¡å—çš„æ³¨æ„åŠ›å¤šæ ·æ€§
        if p_attention is not None:
            diversity_scores['p_attention_diversity'] = compute_head_diversity(p_attention)
        
        if c_attention is not None:
            diversity_scores['c_attention_diversity'] = compute_head_diversity(c_attention)
            
        if s_attention is not None:
            diversity_scores['s_attention_diversity'] = compute_head_diversity(s_attention)
        
        # è®¡ç®—æ•´ä½“32å¤´çš„å¤šæ ·æ€§
        if all(x is not None for x in [p_attention, c_attention, s_attention]):
            # æ‹¼æ¥æ‰€æœ‰æ³¨æ„åŠ›å¤´
            all_attention = torch.cat([p_attention, c_attention, s_attention], dim=1)
            diversity_scores['total_32_head_diversity'] = compute_head_diversity(all_attention)
        
        return diversity_scores
    
    def compute_role_differentiation(self,
                                   p_output: Dict[str, Any],
                                   c_output: Dict[str, Any],
                                   s_output: Dict[str, Any]) -> Dict[str, float]:
        """
        è®¡ç®—è§’è‰²åˆ†åŒ–æŒ‡æ ‡ï¼Œç¡®ä¿Pã€Cã€Sä¿æŒä¸åŒçš„è§’è‰²
        
        Returns:
            è§’è‰²åˆ†åŒ–æŒ‡æ ‡
        """
        metrics = {}
        
        # è·å–éšçŠ¶æ€
        p_hidden = p_output.get('hidden_states')
        c_hidden = c_output.get('hidden_states')
        s_hidden = s_output.get('hidden_states')
        
        if all(x is not None for x in [p_hidden, c_hidden, s_hidden]):
            # è®¡ç®—è§’è‰²ç›¸ä¼¼åº¦ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
            with torch.no_grad():
                # æ± åŒ–éšçŠ¶æ€
                p_pooled = p_hidden.mean(dim=1)
                c_pooled = c_hidden.mean(dim=1)
                s_pooled = s_hidden.mean(dim=1)
                
                # è®¡ç®—ä¸¤ä¸¤ç›¸ä¼¼åº¦
                sim_pc = F.cosine_similarity(p_pooled, c_pooled, dim=-1).mean().item()
                sim_ps = F.cosine_similarity(p_pooled, s_pooled, dim=-1).mean().item()
                sim_cs = F.cosine_similarity(c_pooled, s_pooled, dim=-1).mean().item()
                
                metrics['proposer_challenger_similarity'] = sim_pc
                metrics['proposer_synthesizer_similarity'] = sim_ps
                metrics['challenger_synthesizer_similarity'] = sim_cs
                
                # è§’è‰²åˆ†åŒ–åº¦ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
                avg_similarity = (sim_pc + sim_ps + sim_cs) / 3
                metrics['role_differentiation'] = 1.0 - avg_similarity
                
                # è§’è‰²åå¡Œé£é™©
                max_similarity = max(sim_pc, sim_ps, sim_cs)
                metrics['role_collapse_risk'] = max_similarity
        
        return metrics
    
    def compute_thinking_quality(self, s_output: Dict[str, Any]) -> Dict[str, float]:
        """
        è¯„ä¼°Synthesizerç”Ÿæˆçš„thinkingè´¨é‡
        
        Returns:
            thinkingè´¨é‡æŒ‡æ ‡
        """
        metrics = {}
        
        thinking = s_output.get('thinking')
        if thinking is not None:
            with torch.no_grad():
                # thinkingçš„ä¿¡æ¯ç†µï¼ˆå¤šæ ·æ€§ï¼‰
                thinking_flat = thinking.view(thinking.size(0), -1)
                thinking_probs = F.softmax(thinking_flat, dim=-1)
                entropy = -torch.sum(thinking_probs * torch.log(thinking_probs + 1e-8), dim=-1)
                metrics['thinking_entropy'] = entropy.mean().item()
                
                # thinkingçš„ç¨€ç–åº¦
                sparsity = (thinking.abs() < 1e-6).float().mean().item()
                metrics['thinking_sparsity'] = sparsity
                
                # thinkingçš„æ¿€æ´»å¼ºåº¦
                metrics['thinking_activation_mean'] = thinking.abs().mean().item()
                metrics['thinking_activation_std'] = thinking.std().item()
        
        # ä»s_outputä¸­è·å–è´¨é‡è¯„åˆ†
        if 'thinking_quality' in s_output:
            metrics['thinking_quality_score'] = s_output['thinking_quality'].mean().item()
        
        if 'integration_scores' in s_output:
            metrics['integration_score'] = s_output['integration_scores'].mean().item()
        
        return metrics
    
    def compute_all_metrics(self,
                          outputs: Dict[str, Any],
                          targets: Optional[torch.Tensor] = None,
                          computation_time: Optional[float] = None) -> Dict[str, float]:
        """
        è®¡ç®—æ‰€æœ‰V6æ¶æ„ç›¸å…³æŒ‡æ ‡
        
        Args:
            outputs: æ¨¡å‹è¾“å‡ºå­—å…¸
            targets: ç›®æ ‡æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
            computation_time: è®¡ç®—æ—¶é—´ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ‰€æœ‰æŒ‡æ ‡çš„å­—å…¸
        """
        all_metrics = {}
        
        # è·å–CoDè¾“å‡º
        cod_outputs = outputs.get('cod_outputs', {})
        p_output = cod_outputs.get('proposer', {})
        c_output = cod_outputs.get('challenger', {})
        s_output = cod_outputs.get('synthesizer', {})
        
        # 1. Flowè´¨é‡æŒ‡æ ‡
        if all('hidden_states' in x for x in [p_output, c_output, s_output]):
            flow_metrics = self.compute_flow_quality(
                p_output['hidden_states'],
                c_output['hidden_states'],
                s_output['hidden_states']
            )
            all_metrics.update(flow_metrics)
        
        # 2. æ³¨æ„åŠ›å¤šæ ·æ€§æŒ‡æ ‡
        attention_metrics = self.compute_attention_diversity(
            p_output.get('attention_patterns'),
            c_output.get('attention_patterns'),
            s_output.get('attention_patterns')
        )
        all_metrics.update(attention_metrics)
        
        # 3. è§’è‰²åˆ†åŒ–æŒ‡æ ‡
        if cod_outputs:
            role_metrics = self.compute_role_differentiation(p_output, c_output, s_output)
            all_metrics.update(role_metrics)
        
        # 4. æ€ç»´è´¨é‡æŒ‡æ ‡
        thinking_metrics = self.compute_thinking_quality(s_output)
        all_metrics.update(thinking_metrics)
        
        # 5. æ€§èƒ½æŒ‡æ ‡
        if computation_time is not None:
            all_metrics['computation_time'] = computation_time
        
        # 6. ä»»åŠ¡ç›¸å…³æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰targetsï¼‰
        if targets is not None and 'logits' in outputs:
            logits = outputs['logits']
            if logits.dim() == 3:  # ç”Ÿæˆä»»åŠ¡
                # è®¡ç®—å›°æƒ‘åº¦
                loss = F.cross_entropy(
                    logits.view(-1, logits.size(-1)),
                    targets.view(-1),
                    reduction='mean'
                )
                all_metrics['perplexity'] = torch.exp(loss).item()
            else:  # åˆ†ç±»ä»»åŠ¡
                # è®¡ç®—å‡†ç¡®ç‡
                predictions = torch.argmax(logits, dim=-1)
                accuracy = (predictions == targets).float().mean().item()
                all_metrics['accuracy'] = accuracy
        
        # 7. V6ç‰¹å®šæŒ‡æ ‡
        all_metrics['num_attention_heads'] = 32  # P(10) + C(10) + S(12)
        all_metrics['uses_flow_attention'] = True
        all_metrics['uses_implicit_thinking'] = self._check_implicit_thinking(outputs)
        
        # ç´¯ç§¯æŒ‡æ ‡
        self._accumulate_metrics(all_metrics)
        
        return all_metrics
    
    def _check_implicit_thinking(self, outputs: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†éšå¼thinkingä¼ é€’"""
        # å¯ä»¥é€šè¿‡æ£€æŸ¥æ˜¯å¦æœ‰roundtable attentionçš„è°ƒåˆ¶æ¥åˆ¤æ–­
        return outputs.get('uses_roundtable', False)
    
    def _accumulate_metrics(self, metrics: Dict[str, float]):
        """ç´¯ç§¯æ‰¹æ¬¡æŒ‡æ ‡ç”¨äºè®¡ç®—å¹³å‡å€¼"""
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                self.metrics_accumulator[key].append(value)
        self.batch_count += 1
    
    def get_average_metrics(self) -> Dict[str, float]:
        """è·å–æ‰€æœ‰æ‰¹æ¬¡çš„å¹³å‡æŒ‡æ ‡"""
        avg_metrics = {}
        for key, values in self.metrics_accumulator.items():
            if values:
                avg_metrics[key] = np.mean(values)
        avg_metrics['total_batches'] = self.batch_count
        return avg_metrics
    
    def print_metrics_summary(self, metrics: Dict[str, float]):
        """æ‰“å°æŒ‡æ ‡æ‘˜è¦"""
        print("\n" + "="*60)
        print("CoD V6 è¯„ä¼°æŒ‡æ ‡æ‘˜è¦")
        print("="*60)
        
        # Flowè´¨é‡
        print("\nğŸ“Š Flowè´¨é‡æŒ‡æ ‡:")
        for key in ['flow_coherence', 'p_to_c_retention', 'c_novelty', 's_integration']:
            if key in metrics:
                print(f"  {key}: {metrics[key]:.4f}")
        
        # æ³¨æ„åŠ›å¤šæ ·æ€§
        print("\nğŸ¯ æ³¨æ„åŠ›å¤šæ ·æ€§:")
        for key in ['total_32_head_diversity', 'p_attention_diversity', 
                    'c_attention_diversity', 's_attention_diversity']:
            if key in metrics:
                print(f"  {key}: {metrics[key]:.4f}")
        
        # è§’è‰²åˆ†åŒ–
        print("\nğŸ‘¥ è§’è‰²åˆ†åŒ–:")
        for key in ['role_differentiation', 'role_collapse_risk']:
            if key in metrics:
                print(f"  {key}: {metrics[key]:.4f}")
        
        # æ€ç»´è´¨é‡
        print("\nğŸ§  æ€ç»´è´¨é‡:")
        for key in ['thinking_quality_score', 'thinking_entropy', 'integration_score']:
            if key in metrics:
                print(f"  {key}: {metrics[key]:.4f}")
        
        # æ€§èƒ½æŒ‡æ ‡
        print("\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
        if 'computation_time' in metrics:
            print(f"  è®¡ç®—æ—¶é—´: {metrics['computation_time']:.3f}s")
        if 'perplexity' in metrics:
            print(f"  å›°æƒ‘åº¦: {metrics['perplexity']:.2f}")
        if 'accuracy' in metrics:
            print(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
        
        print("="*60) 