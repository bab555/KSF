#!/usr/bin/env python3
"""
KSF (Knowledge Synthesized Framework) ä¸»è®­ç»ƒè„šæœ¬
ä½¿ç”¨K-Sæ¶æ„è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒ
"""

import os
import sys
import yaml
import logging
import argparse
from pathlib import Path

import torch
import torch.multiprocessing as mp

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from ksf.training.trainer import KsfTrainer


def setup_logging(config: dict):
    """è®¾ç½®æ—¥å¿—"""
    log_config = config.get('logging', {})
    log_level = getattr(logging, log_config.get('level', 'INFO'))
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = Path(log_config.get('log_dir', './logs/ksf'))
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(log_dir / 'training.log')
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info("KSFè®­ç»ƒæ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–")
    return logger


def validate_config(config: dict) -> bool:
    """éªŒè¯é…ç½®æ–‡ä»¶çš„å®Œæ•´æ€§"""
    required_sections = ['base_model', 'model', 'training', 'data', 'loss']
    
    for section in required_sections:
        if section not in config:
            print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„èŠ‚: {section}")
            return False
    
    # éªŒè¯æ•°æ®æ–‡ä»¶è·¯å¾„
    data_config = config['data']
    train_file = data_config.get('train_file')
    eval_file = data_config.get('eval_file')
    
    if not train_file or not Path(train_file).exists():
        print(f"âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
        return False
    
    if not eval_file or not Path(eval_file).exists():
        print(f"âŒ éªŒè¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {eval_file}")
        return False
    
    # éªŒè¯åŸºç¡€æ¨¡å‹è·¯å¾„
    base_model_path = config['base_model'].get('path')
    if not base_model_path or not Path(base_model_path).exists():
        print(f"âŒ åŸºç¡€æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {base_model_path}")
        return False
    
    print("âœ… é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
    return True


def check_environment():
    """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0)
        memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"âœ… GPU: {gpu_name} ({memory:.1f}GB)")
        print(f"âœ… GPUæ•°é‡: {gpu_count}")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°CUDAï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    
    # æ£€æŸ¥å†…å­˜
    import psutil
    memory_gb = psutil.virtual_memory().total / 1024**3
    print(f"âœ… ç³»ç»Ÿå†…å­˜: {memory_gb:.1f}GB")
    
    # æ£€æŸ¥Pythonç¯å¢ƒ
    print(f"âœ… Pythonç‰ˆæœ¬: {sys.version}")
    print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")


def load_config(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path(config_path)
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
    return config


def create_sample_data(data_dir: Path):
    """åˆ›å»ºç¤ºä¾‹è®­ç»ƒæ•°æ®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
    train_file = data_dir / 'ksf_train.jsonl'
    eval_file = data_dir / 'ksf_eval.jsonl'
    
    if train_file.exists() and eval_file.exists():
        return
    
    print("ğŸ“ åˆ›å»ºç¤ºä¾‹è®­ç»ƒæ•°æ®...")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # ç¤ºä¾‹æ•°æ®
    import json
    
    sample_data = [
        {
            "query": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "knowledge": "äººå·¥æ™ºèƒ½(AI)æ˜¯æŒ‡æœºå™¨æ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬å­¦ä¹ ã€æ¨ç†ã€æ„ŸçŸ¥ã€ç†è§£è¯­è¨€ç­‰ã€‚",
            "answer": "äººå·¥æ™ºèƒ½æ˜¯è®©æœºå™¨å…·å¤‡ç±»ä¼¼äººç±»æ™ºèƒ½çš„æŠ€æœ¯ï¼Œèƒ½å¤Ÿå­¦ä¹ ã€æ¨ç†å’Œè§£å†³é—®é¢˜ã€‚"
        },
        {
            "query": "æœºå™¨å­¦ä¹ çš„åŸºæœ¬ç±»å‹æœ‰å“ªäº›ï¼Ÿ",
            "knowledge": "æœºå™¨å­¦ä¹ ä¸»è¦åˆ†ä¸ºç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ä¸‰ç§ç±»å‹ã€‚ç›‘ç£å­¦ä¹ ä½¿ç”¨æ ‡è®°æ•°æ®è®­ç»ƒæ¨¡å‹ã€‚",
            "answer": "æœºå™¨å­¦ä¹ ä¸»è¦åŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ä¸‰ç§åŸºæœ¬ç±»å‹ã€‚"
        },
        {
            "query": "æ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
            "knowledge": "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚æ¨¡å¼ï¼Œè€Œä¼ ç»Ÿæœºå™¨å­¦ä¹ é€šå¸¸ä½¿ç”¨è¾ƒç®€å•çš„ç®—æ³•å’Œæ‰‹å·¥ç‰¹å¾ã€‚",
            "answer": "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œè‡ªåŠ¨å­¦ä¹ ç‰¹å¾ï¼Œè€Œä¼ ç»Ÿæœºå™¨å­¦ä¹ ä¾èµ–æ‰‹å·¥è®¾è®¡çš„ç‰¹å¾ã€‚"
        }
    ]
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®
    with open(train_file, 'w', encoding='utf-8') as f:
        for item in sample_data * 100:  # é‡å¤æ•°æ®ä»¥å¢åŠ æ ·æœ¬é‡
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    # åˆ›å»ºéªŒè¯æ•°æ®
    with open(eval_file, 'w', encoding='utf-8') as f:
        for item in sample_data * 10:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"âœ… ç¤ºä¾‹æ•°æ®å·²åˆ›å»º: {train_file}, {eval_file}")


def main():
    # Setup basic logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # Argument parser
    parser = argparse.ArgumentParser(description="Train the KSF model.")
    parser.add_argument(
        '--config',
        type=str,
        default='configs/ksf_training_config.yaml',
        help='Path to the training configuration file.'
    )
    args = parser.parse_args()

    # Initialize and run the trainer
    try:
        trainer = KsfTrainer(config_path=args.config)
        trainer.train()
    except Exception as e:
        logging.error("An error occurred during the training process.", exc_info=True)


if __name__ == '__main__':
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
    if mp.get_start_method(allow_none=True) != 'spawn':
        mp.set_start_method('spawn', force=True)
    
    main() 